//
//  Created by ktiays on 2025/2/12.
//  Copyright (c) 2025 ktiays. All rights reserved.
//

import Foundation

/// Chat completion request body. Docstrings are taken from this reference:
/// https://platform.openai.com/docs/api-reference/chat/create
public struct ChatRequestBody: Sendable, Encodable {
    var model: String?

    public let messages: [Message]

    public let maxCompletionTokens: Int?

    public var stream: Bool?

    public let temperature: Double?

    public let tools: [Tool]?

    private enum CodingKeys: String, CodingKey {
        // required
        case model
        case messages

        // optional
        case maxCompletionTokens = "max_completion_tokens"
        case stream
        case temperature
        case tools
    }

    public init(
        messages: [Message],
        maxCompletionTokens: Int? = nil,
        stream: Bool? = nil,
        temperature: Double? = nil,
        tools: [Tool]? = nil
    ) {
        model = nil
        self.messages = messages
        self.maxCompletionTokens = maxCompletionTokens
        self.stream = stream
        self.temperature = temperature
        self.tools = tools
    }
}

public extension ChatRequestBody {
    /// https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages
    enum Message: Sendable, Encodable {
        /// Messages sent by the model in response to user messages
        ///
        /// - Parameters:
        ///   - content: The contents of the assistant message. Can be a single string or multiple strings
        ///   - name: An optional name for the participant. Provides the model information to differentiate
        ///           between participants of the same role.
        ///   - refusal: The refusal message by the assistant.
        ///   - toolCalls: The tool calls generated by the model, such as function calls.
        case assistant(
            content: MessageContent<String, [String]>? = nil,
            name: String? = nil,
            refusal: String? = nil,
            toolCalls: [ToolCall]? = nil
        )

        /// Developer-provided instructions that the model should follow, regardless of messages sent by the user.
        /// With o1 models and newer, `developer` messages replace the previous `system` messages.
        ///
        /// - Parameters:
        ///   - content: The contents of the developer message. Can be a single string or multiple strings
        ///   - name: An optional name for the participant. Provides the model information to differentiate
        ///           between participants of the same role.
        case developer(
            content: MessageContent<String, [String]>,
            name: String? = nil
        )

        /// Developer-provided instructions that the model should follow, regardless of messages sent by the user. With o1 models and newer, use `developer` messages for this purpose instead.
        ///
        /// - Parameters:
        ///   - content: The contents of the system message. Can be a single string or multiple strings
        ///   - name: An optional name for the participant. Provides the model information to differentiate
        ///           between participants of the same role.
        case system(
            content: MessageContent<String, [String]>,
            name: String? = nil
        )

        case tool(
            content: MessageContent<String, [String]>,
            toolCallID: String
        )

        /// Messages sent by an end user, containing prompts or additional context information.
        ///
        /// - Parameters:
        ///   - content: The contents of the user message.
        ///              The contents can be a single string or an array of content parts.
        ///              Content parts can be text, image, or audio.
        ///              You can pass multiple images by adding multiple imageURL content parts.
        ///              Image input is only supported when using the gpt-4o model.
        ///   - name: An optional name for the participant. Provides the model information to differentiate
        ///           between participants of the same role.
        case user(
            content: MessageContent<String, [ContentPart]>,
            name: String? = nil
        )

        var role: String {
            switch self {
            case .assistant: "assistant"
            case .developer: "developer"
            case .system: "system"
            case .tool: "tool"
            case .user: "user"
            }
        }

        private enum RootKey: String, CodingKey, Equatable {
            case content
            case name
            case refusal
            case role
            case toolCallID = "tool_call_id"
            case toolCalls = "tool_calls"
        }

        public func encode(to encoder: any Encoder) throws {
            var container = encoder.container(keyedBy: RootKey.self)
            try container.encode(role, forKey: .role)
            switch self {
            case let .assistant(content, name, refusal, toolCalls):
                try container.encodeIfPresent(content, forKey: .content)
                try container.encodeIfPresent(name, forKey: .name)
                try container.encodeIfPresent(refusal, forKey: .refusal)
                try container.encodeIfPresent(toolCalls, forKey: .toolCalls)
            case let .developer(content, name):
                try container.encode(content, forKey: .content)
                try container.encodeIfPresent(name, forKey: .name)
            case let .system(content, name):
                try container.encode(content, forKey: .content)
                try container.encodeIfPresent(name, forKey: .name)
            case let .tool(content, toolCallID):
                try container.encode(content, forKey: .content)
                try container.encode(toolCallID, forKey: .toolCallID)
            case let .user(content, name):
                try container.encode(content, forKey: .content)
                try container.encodeIfPresent(name, forKey: .name)
            }
        }
    }
}

public extension ChatRequestBody.Message {
    enum MessageContent<SingleType, PartsType>: @unchecked Sendable, Encodable, SingleOrPartsEncodable where SingleType: Encodable, PartsType: Encodable {
        case text(SingleType)
        case parts(PartsType)

        var encodableItem: Encodable {
            switch self {
            case let .text(single):
                single
            case let .parts(parts):
                parts
            }
        }
    }
}

public extension ChatRequestBody.Message {
    enum ContentPart: Sendable, Encodable {
        /// The text content.
        case text(String)

        /// The URL is a "local URL" containing base64 encoded image data.
        ///
        /// By controlling the detail parameter, which has three options, low, high, or auto, you have control over
        /// how the model processes the image and generates its textual understanding. By default, the model will use
        /// the auto setting which will look at the image input size and decide if it should use the low or high setting.
        ///
        /// "low" will enable the "low res" mode. The model will receive a low-res 512px x 512px version of the image, and
        /// represent the image with a budget of 85 tokens. This allows the API to return faster responses and consume
        /// fewer input tokens for use cases that do not require high detail.
        ///
        /// "high" will enable "high res" mode, which first allows the model to first see the low res image (using 85
        /// tokens) and then creates detailed crops using 170 tokens for each 512px x 512px tile.
        case imageURL(URL, detail: ImageDetail? = nil)

        /// Base64 encoded audio content that should be provided to models supporting audio input.
        /// The format parameter describes the container or codec (e.g. "wav").
        case audioBase64(String, format: String)

        private enum RootKey: String, CodingKey {
            case type
            case text
            case imageURL = "image_url"
            case audio = "input_audio"
        }

        private enum ImageKey: CodingKey {
            case url
            case detail
        }

        private enum AudioKey: CodingKey {
            case data
            case format
        }

        public func encode(to encoder: any Encoder) throws {
            var container = encoder.container(keyedBy: RootKey.self)
            switch self {
            case let .text(text):
                try container.encode("text", forKey: .type)
                try container.encode(text, forKey: .text)
            case let .imageURL(url, detail):
                try container.encode("image_url", forKey: .type)
                var nestedContainer = container.nestedContainer(
                    keyedBy: ImageKey.self, forKey: .imageURL
                )
                try nestedContainer.encode(url, forKey: .url)
                if let detail {
                    try nestedContainer.encode(detail, forKey: .detail)
                }
            case let .audioBase64(data, format):
                try container.encode("input_audio", forKey: .type)
                var nestedContainer = container.nestedContainer(
                    keyedBy: AudioKey.self,
                    forKey: .audio
                )
                try nestedContainer.encode(data, forKey: .data)
                try nestedContainer.encode(format, forKey: .format)
            }
        }
    }
}

public extension ChatRequestBody.Message.ContentPart {
    enum ImageDetail: String, Sendable, Encodable {
        case auto
        case low
        case high
    }
}

public extension ChatRequestBody.Message {
    struct ToolCall: Sendable, Encodable {
        /// The ID of the tool call.
        let id: String

        /// The type of the tool. Currently, only `function` is supported.
        let type = "function"

        /// The function that the model called
        let function: Function

        public init(
            id: String,
            function: ChatRequestBody.Message.ToolCall.Function
        ) {
            self.id = id
            self.function = function
        }
    }
}

public extension ChatRequestBody.Message.ToolCall {
    /// Represents the 'Function' object at `messages > assistant message > tool_calls > function`
    /// https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages
    struct Function: Sendable, Encodable {
        /// The name of the function that the assistant asked you to call.
        public let name: String

        /// The arguments that the assistant asked you to call your function with.
        /// After you call the function natively, you pass this information back up to OpenAI to continue the conversation.
        public let arguments: String?

        public init(
            name: String,
            arguments: String? = nil
        ) {
            self.name = name
            self.arguments = arguments
        }
    }
}

public extension ChatRequestBody {
    enum Tool: Sendable, Encodable {
        /// A function that chatGPT can instruct us to call when appropriate
        ///
        /// - Parameters:
        ///   - name: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
        ///           dashes, with a maximum length of 64.
        ///
        ///   - description: A description of what the function does, used by the model to choose when and how to
        ///                  call the function.
        ///
        ///   - parameters: The parameters the functions accepts, described as a JSON Schema object. See the guide
        ///                 for examples, and the JSON Schema reference for documentation about the format.
        ///                 Omitting `parameters` defines a function with an empty parameter list.
        ///                 Function calling guide: https://platform.openai.com/docs/guides/function-calling
        ///                 JSON schema reference: https://json-schema.org/understanding-json-schema
        ///
        ///   - strict: Whether to enable strict schema adherence when generating the function call. If set to
        ///             true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON
        ///             Schema is supported when strict is true. Learn more about Structured Outputs in the function calling
        ///             guide: https://platform.openai.com/docs/api-reference/chat/docs/guides/function-calling
        case function(
            name: String,
            description: String?,
            parameters: [String: AnyCodingValue]?,
            strict: Bool?
        )

        private enum RootKey: CodingKey {
            case type
            case function
        }

        private enum FunctionKey: CodingKey {
            case description
            case name
            case parameters
            case strict
        }

        public func encode(to encoder: any Encoder) throws {
            var container = encoder.container(keyedBy: RootKey.self)
            switch self {
            case let .function(
                name: name,
                description: description,
                parameters: parameters,
                strict: strict
            ):
                try container.encode("function", forKey: .type)
                var functionContainer = container.nestedContainer(
                    keyedBy: FunctionKey.self,
                    forKey: .function
                )
                try functionContainer.encode(name, forKey: .name)
                try functionContainer.encodeIfPresent(description, forKey: .description)
                try functionContainer.encodeIfPresent(parameters, forKey: .parameters)
                try functionContainer.encodeIfPresent(strict, forKey: .strict)
            }
        }
    }
}
